{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정책 기반 에이전트 - REINFORCE 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REINFORCE algorithm for CartPole 동작 과정 요약 (On-policy)\n",
    "\n",
    "for n_epi in range(10000):\n",
    "\n",
    "    while not done: # 한 episode 동안 ..\n",
    "        # 각 state에서, 각 action에 대한 prob를 계산\n",
    "        # prob에 비례하게 action을 선택\n",
    "        # 해당 action에 대한 reward와 prob를 저장(put_data)\n",
    "        # transition\n",
    "\n",
    "    pi.train_net() \n",
    "    # 하나의 episode동안 모은 데이터를 이용해 parameter update를 실시\n",
    "    # 이때, G_t를 구해야 하기 때문에, episode의 뒤부터 훑으면서 state별 gradient를 계산\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 라이브러리 Import 및 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "gamma = 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정책 네트워크 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 2) # 취할 수 있는 Action의 개수가 2개이므로\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim = 0)\n",
    "        return x # 2개의 action에 대한 확률값 return\n",
    "    \n",
    "    def put_data(self, item): # REINFORCE 알고리즘에서는 pi_theta(s_t, a_t)와 G_t만 있으면 loss를 계산할 수 있기 때문에 확률값 prob[a]와 보상 r을 데이터에 저장\n",
    "        self.data.append(item)\n",
    "\n",
    "    def train_net(self):\n",
    "        R = 0\n",
    "        self.optimizer.zero_grad() # gradient 초기화(pytorch에서는 step을 거치며 이전 gradient를 계속 누적시키기 때문에)\n",
    "        for r, prob in self.data[::-1]:\n",
    "            R = r + gamma * R # Episode의 맨 뒤의 데이터부터 보면서 reward를 누적 (따라서 R은 G_t)\n",
    "            loss = - R * torch.log(prob) # Gradient Ascent를 하기 위해서 -를 붙임 / 더 좋은 액션을 강화하는 형태\n",
    "            loss.backward() # loss를 계산한 후 각 파라미터에 대해 미분값을 계산 (누적)\n",
    "            # print(\"n_epi : \", n_epi, \"Loss : \", loss)\n",
    "        self.optimizer.step() # parameter 업데이트\n",
    "        self.data = [] # 데이터 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 메인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of episode : 20, avg score : 35.15\n",
      "# of episode : 40, avg score : 24.95\n",
      "# of episode : 60, avg score : 30.65\n",
      "# of episode : 80, avg score : 33.1\n",
      "# of episode : 100, avg score : 32.55\n",
      "# of episode : 120, avg score : 26.7\n",
      "# of episode : 140, avg score : 35.25\n",
      "# of episode : 160, avg score : 28.15\n",
      "# of episode : 180, avg score : 35.3\n",
      "# of episode : 200, avg score : 33.3\n",
      "# of episode : 220, avg score : 28.7\n",
      "# of episode : 240, avg score : 33.35\n",
      "# of episode : 260, avg score : 42.6\n",
      "# of episode : 280, avg score : 47.55\n",
      "# of episode : 300, avg score : 36.2\n",
      "# of episode : 320, avg score : 45.55\n",
      "# of episode : 340, avg score : 40.15\n",
      "# of episode : 360, avg score : 37.15\n",
      "# of episode : 380, avg score : 42.7\n",
      "# of episode : 400, avg score : 42.3\n",
      "# of episode : 420, avg score : 37.9\n",
      "# of episode : 440, avg score : 39.15\n",
      "# of episode : 460, avg score : 36.85\n",
      "# of episode : 480, avg score : 44.75\n",
      "# of episode : 500, avg score : 44.65\n",
      "# of episode : 520, avg score : 46.85\n",
      "# of episode : 540, avg score : 56.35\n",
      "# of episode : 560, avg score : 39.35\n",
      "# of episode : 580, avg score : 48.05\n",
      "# of episode : 600, avg score : 62.8\n",
      "# of episode : 620, avg score : 58.6\n",
      "# of episode : 640, avg score : 60.5\n",
      "# of episode : 660, avg score : 58.05\n",
      "# of episode : 680, avg score : 56.8\n",
      "# of episode : 700, avg score : 59.2\n",
      "# of episode : 720, avg score : 74.5\n",
      "# of episode : 740, avg score : 64.5\n",
      "# of episode : 760, avg score : 56.35\n",
      "# of episode : 780, avg score : 76.3\n",
      "# of episode : 800, avg score : 70.0\n",
      "# of episode : 820, avg score : 79.0\n",
      "# of episode : 840, avg score : 91.15\n",
      "# of episode : 860, avg score : 102.35\n",
      "# of episode : 880, avg score : 107.25\n",
      "# of episode : 900, avg score : 80.35\n",
      "# of episode : 920, avg score : 100.45\n",
      "# of episode : 940, avg score : 127.35\n",
      "# of episode : 960, avg score : 127.05\n",
      "# of episode : 980, avg score : 109.15\n",
      "# of episode : 1000, avg score : 114.75\n",
      "# of episode : 1020, avg score : 123.05\n",
      "# of episode : 1040, avg score : 139.55\n",
      "# of episode : 1060, avg score : 123.05\n",
      "# of episode : 1080, avg score : 121.0\n",
      "# of episode : 1100, avg score : 171.7\n",
      "# of episode : 1120, avg score : 151.05\n",
      "# of episode : 1140, avg score : 172.9\n",
      "# of episode : 1160, avg score : 166.8\n",
      "# of episode : 1180, avg score : 184.1\n",
      "# of episode : 1200, avg score : 167.5\n",
      "# of episode : 1220, avg score : 154.3\n",
      "# of episode : 1240, avg score : 189.5\n",
      "# of episode : 1260, avg score : 152.35\n",
      "# of episode : 1280, avg score : 149.05\n",
      "# of episode : 1300, avg score : 152.75\n",
      "# of episode : 1320, avg score : 161.65\n",
      "# of episode : 1340, avg score : 154.0\n",
      "# of episode : 1360, avg score : 140.95\n",
      "# of episode : 1380, avg score : 219.85\n",
      "# of episode : 1400, avg score : 167.0\n",
      "# of episode : 1420, avg score : 153.75\n",
      "# of episode : 1440, avg score : 182.9\n",
      "# of episode : 1460, avg score : 201.4\n",
      "# of episode : 1480, avg score : 219.3\n",
      "# of episode : 1500, avg score : 215.75\n",
      "# of episode : 1520, avg score : 200.25\n",
      "# of episode : 1540, avg score : 228.3\n",
      "# of episode : 1560, avg score : 179.8\n",
      "# of episode : 1580, avg score : 225.1\n",
      "# of episode : 1600, avg score : 173.65\n",
      "# of episode : 1620, avg score : 156.9\n",
      "# of episode : 1640, avg score : 166.35\n",
      "# of episode : 1660, avg score : 219.05\n",
      "# of episode : 1680, avg score : 251.15\n",
      "# of episode : 1700, avg score : 238.7\n",
      "# of episode : 1720, avg score : 254.75\n",
      "# of episode : 1740, avg score : 253.75\n",
      "# of episode : 1760, avg score : 298.3\n",
      "# of episode : 1780, avg score : 291.0\n",
      "# of episode : 1800, avg score : 270.05\n",
      "# of episode : 1820, avg score : 281.3\n",
      "# of episode : 1840, avg score : 347.85\n",
      "# of episode : 1860, avg score : 298.2\n",
      "# of episode : 1880, avg score : 272.35\n",
      "# of episode : 1900, avg score : 309.7\n",
      "# of episode : 1920, avg score : 334.65\n",
      "# of episode : 1940, avg score : 277.35\n",
      "# of episode : 1960, avg score : 308.6\n",
      "# of episode : 1980, avg score : 315.35\n",
      "# of episode : 2000, avg score : 373.35\n",
      "# of episode : 2020, avg score : 307.45\n",
      "# of episode : 2040, avg score : 303.05\n",
      "# of episode : 2060, avg score : 267.1\n",
      "# of episode : 2080, avg score : 267.4\n",
      "# of episode : 2100, avg score : 288.55\n",
      "# of episode : 2120, avg score : 300.15\n",
      "# of episode : 2140, avg score : 326.35\n",
      "# of episode : 2160, avg score : 262.7\n",
      "# of episode : 2180, avg score : 338.4\n",
      "# of episode : 2200, avg score : 334.4\n",
      "# of episode : 2220, avg score : 376.1\n",
      "# of episode : 2240, avg score : 375.55\n",
      "# of episode : 2260, avg score : 268.65\n",
      "# of episode : 2280, avg score : 227.5\n",
      "# of episode : 2300, avg score : 295.65\n",
      "# of episode : 2320, avg score : 261.75\n",
      "# of episode : 2340, avg score : 303.4\n",
      "# of episode : 2360, avg score : 338.1\n",
      "# of episode : 2380, avg score : 342.25\n",
      "# of episode : 2400, avg score : 295.75\n",
      "# of episode : 2420, avg score : 327.4\n",
      "# of episode : 2440, avg score : 413.5\n",
      "# of episode : 2460, avg score : 380.2\n",
      "# of episode : 2480, avg score : 387.45\n",
      "# of episode : 2500, avg score : 349.3\n",
      "# of episode : 2520, avg score : 359.9\n",
      "# of episode : 2540, avg score : 291.3\n",
      "# of episode : 2560, avg score : 362.4\n",
      "# of episode : 2580, avg score : 306.6\n",
      "# of episode : 2600, avg score : 444.9\n",
      "# of episode : 2620, avg score : 351.75\n",
      "# of episode : 2640, avg score : 323.25\n",
      "# of episode : 2660, avg score : 357.85\n",
      "# of episode : 2680, avg score : 336.45\n",
      "# of episode : 2700, avg score : 351.8\n",
      "# of episode : 2720, avg score : 343.6\n",
      "# of episode : 2740, avg score : 390.45\n",
      "# of episode : 2760, avg score : 243.8\n",
      "# of episode : 2780, avg score : 398.4\n",
      "# of episode : 2800, avg score : 378.15\n",
      "# of episode : 2820, avg score : 397.0\n",
      "# of episode : 2840, avg score : 432.1\n",
      "# of episode : 2860, avg score : 475.6\n",
      "# of episode : 2880, avg score : 434.35\n",
      "# of episode : 2900, avg score : 396.15\n",
      "# of episode : 2920, avg score : 366.6\n",
      "# of episode : 2940, avg score : 373.2\n",
      "# of episode : 2960, avg score : 292.05\n",
      "# of episode : 2980, avg score : 302.35\n",
      "# of episode : 3000, avg score : 401.45\n",
      "# of episode : 3020, avg score : 281.4\n",
      "# of episode : 3040, avg score : 350.65\n",
      "# of episode : 3060, avg score : 360.85\n",
      "# of episode : 3080, avg score : 435.95\n",
      "# of episode : 3100, avg score : 414.1\n",
      "# of episode : 3120, avg score : 471.1\n",
      "# of episode : 3140, avg score : 653.1\n",
      "# of episode : 3160, avg score : 439.3\n",
      "# of episode : 3180, avg score : 540.85\n",
      "# of episode : 3200, avg score : 480.35\n",
      "# of episode : 3220, avg score : 464.55\n",
      "# of episode : 3240, avg score : 598.45\n",
      "# of episode : 3260, avg score : 461.8\n",
      "# of episode : 3280, avg score : 447.75\n",
      "# of episode : 3300, avg score : 504.8\n",
      "# of episode : 3320, avg score : 479.45\n",
      "# of episode : 3340, avg score : 533.1\n",
      "# of episode : 3360, avg score : 416.2\n",
      "# of episode : 3380, avg score : 436.15\n",
      "# of episode : 3400, avg score : 529.05\n",
      "# of episode : 3420, avg score : 652.0\n",
      "# of episode : 3440, avg score : 474.5\n",
      "# of episode : 3460, avg score : 418.4\n",
      "# of episode : 3480, avg score : 413.4\n",
      "# of episode : 3500, avg score : 609.0\n",
      "# of episode : 3520, avg score : 511.85\n",
      "# of episode : 3540, avg score : 465.55\n",
      "# of episode : 3560, avg score : 558.45\n",
      "# of episode : 3580, avg score : 290.3\n",
      "# of episode : 3600, avg score : 252.0\n",
      "# of episode : 3620, avg score : 249.55\n",
      "# of episode : 3640, avg score : 228.0\n",
      "# of episode : 3660, avg score : 244.25\n",
      "# of episode : 3680, avg score : 287.4\n",
      "# of episode : 3700, avg score : 345.5\n",
      "# of episode : 3720, avg score : 231.05\n",
      "# of episode : 3740, avg score : 324.3\n",
      "# of episode : 3760, avg score : 408.7\n",
      "# of episode : 3780, avg score : 433.7\n",
      "# of episode : 3800, avg score : 374.85\n",
      "# of episode : 3820, avg score : 447.0\n",
      "# of episode : 3840, avg score : 533.6\n",
      "# of episode : 3860, avg score : 634.1\n",
      "# of episode : 3880, avg score : 522.8\n",
      "# of episode : 3900, avg score : 514.15\n",
      "# of episode : 3920, avg score : 459.55\n",
      "# of episode : 3940, avg score : 474.65\n",
      "# of episode : 3960, avg score : 364.25\n",
      "# of episode : 3980, avg score : 387.65\n",
      "# of episode : 4000, avg score : 652.9\n",
      "# of episode : 4020, avg score : 511.0\n",
      "# of episode : 4040, avg score : 506.5\n",
      "# of episode : 4060, avg score : 541.4\n",
      "# of episode : 4080, avg score : 493.0\n",
      "# of episode : 4100, avg score : 718.55\n",
      "# of episode : 4120, avg score : 623.65\n",
      "# of episode : 4140, avg score : 531.55\n",
      "# of episode : 4160, avg score : 605.95\n",
      "# of episode : 4180, avg score : 490.9\n",
      "# of episode : 4200, avg score : 674.25\n",
      "# of episode : 4220, avg score : 315.55\n",
      "# of episode : 4240, avg score : 430.05\n",
      "# of episode : 4260, avg score : 339.65\n",
      "# of episode : 4280, avg score : 357.7\n",
      "# of episode : 4300, avg score : 369.0\n",
      "# of episode : 4320, avg score : 301.85\n",
      "# of episode : 4340, avg score : 409.65\n",
      "# of episode : 4360, avg score : 337.1\n",
      "# of episode : 4380, avg score : 418.1\n",
      "# of episode : 4400, avg score : 434.05\n",
      "# of episode : 4420, avg score : 404.25\n",
      "# of episode : 4440, avg score : 543.55\n",
      "# of episode : 4460, avg score : 718.15\n",
      "# of episode : 4480, avg score : 691.25\n",
      "# of episode : 4500, avg score : 398.7\n",
      "# of episode : 4520, avg score : 532.6\n",
      "# of episode : 4540, avg score : 662.1\n",
      "# of episode : 4560, avg score : 441.4\n",
      "# of episode : 4580, avg score : 942.55\n",
      "# of episode : 4600, avg score : 546.95\n",
      "# of episode : 4620, avg score : 482.3\n",
      "# of episode : 4640, avg score : 475.0\n",
      "# of episode : 4660, avg score : 390.45\n",
      "# of episode : 4680, avg score : 355.35\n",
      "# of episode : 4700, avg score : 375.5\n",
      "# of episode : 4720, avg score : 317.15\n",
      "# of episode : 4740, avg score : 288.55\n",
      "# of episode : 4760, avg score : 326.45\n",
      "# of episode : 4780, avg score : 452.1\n",
      "# of episode : 4800, avg score : 567.5\n",
      "# of episode : 4820, avg score : 696.1\n",
      "# of episode : 4840, avg score : 715.25\n",
      "# of episode : 4860, avg score : 887.85\n",
      "# of episode : 4880, avg score : 699.8\n",
      "# of episode : 4900, avg score : 777.2\n",
      "# of episode : 4920, avg score : 787.5\n",
      "# of episode : 4940, avg score : 896.0\n",
      "# of episode : 4960, avg score : 963.7\n",
      "# of episode : 4980, avg score : 680.15\n",
      "# of episode : 5000, avg score : 1307.45\n",
      "# of episode : 5020, avg score : 1045.9\n",
      "# of episode : 5040, avg score : 740.4\n",
      "# of episode : 5060, avg score : 832.4\n",
      "# of episode : 5080, avg score : 1079.85\n",
      "# of episode : 5100, avg score : 954.95\n",
      "# of episode : 5120, avg score : 821.75\n",
      "# of episode : 5140, avg score : 710.05\n",
      "# of episode : 5160, avg score : 687.35\n",
      "# of episode : 5180, avg score : 1165.7\n",
      "# of episode : 5200, avg score : 1227.35\n",
      "# of episode : 5220, avg score : 814.05\n",
      "# of episode : 5240, avg score : 1058.05\n",
      "# of episode : 5260, avg score : 961.75\n",
      "# of episode : 5280, avg score : 930.85\n",
      "# of episode : 5300, avg score : 1041.55\n",
      "# of episode : 5320, avg score : 1040.8\n",
      "# of episode : 5340, avg score : 926.7\n",
      "# of episode : 5360, avg score : 1544.35\n",
      "# of episode : 5380, avg score : 1501.2\n",
      "# of episode : 5400, avg score : 1317.85\n",
      "# of episode : 5420, avg score : 1288.25\n",
      "# of episode : 5440, avg score : 1130.5\n",
      "# of episode : 5460, avg score : 972.4\n",
      "# of episode : 5480, avg score : 1023.15\n",
      "# of episode : 5500, avg score : 1270.35\n",
      "# of episode : 5520, avg score : 1814.8\n",
      "# of episode : 5540, avg score : 1444.75\n",
      "# of episode : 5560, avg score : 1140.0\n",
      "# of episode : 5580, avg score : 1122.65\n",
      "# of episode : 5600, avg score : 1349.65\n",
      "# of episode : 5620, avg score : 1693.4\n",
      "# of episode : 5640, avg score : 1373.05\n",
      "# of episode : 5660, avg score : 1300.25\n",
      "# of episode : 5680, avg score : 1656.5\n",
      "# of episode : 5700, avg score : 2284.45\n",
      "# of episode : 5720, avg score : 1535.15\n",
      "# of episode : 5740, avg score : 1378.05\n",
      "# of episode : 5760, avg score : 1835.3\n",
      "# of episode : 5780, avg score : 1283.2\n",
      "# of episode : 5800, avg score : 1503.15\n",
      "# of episode : 5820, avg score : 1181.15\n",
      "# of episode : 5840, avg score : 992.45\n",
      "# of episode : 5860, avg score : 1000.1\n",
      "# of episode : 5880, avg score : 851.7\n",
      "# of episode : 5900, avg score : 1754.45\n",
      "# of episode : 5920, avg score : 1489.9\n",
      "# of episode : 5940, avg score : 2426.95\n",
      "# of episode : 5960, avg score : 3667.9\n",
      "# of episode : 5980, avg score : 2794.35\n",
      "# of episode : 6000, avg score : 2541.8\n",
      "# of episode : 6020, avg score : 3359.65\n",
      "# of episode : 6040, avg score : 2449.9\n",
      "# of episode : 6060, avg score : 1286.4\n",
      "# of episode : 6080, avg score : 1115.2\n",
      "# of episode : 6100, avg score : 1196.7\n",
      "# of episode : 6120, avg score : 1330.9\n",
      "# of episode : 6140, avg score : 2083.55\n",
      "# of episode : 6160, avg score : 1790.85\n",
      "# of episode : 6180, avg score : 3520.7\n",
      "# of episode : 6200, avg score : 4220.0\n",
      "# of episode : 6220, avg score : 4045.45\n",
      "# of episode : 6240, avg score : 3500.15\n",
      "# of episode : 6260, avg score : 5505.95\n",
      "# of episode : 6280, avg score : 6781.6\n",
      "# of episode : 6300, avg score : 1894.9\n",
      "# of episode : 6320, avg score : 959.0\n",
      "# of episode : 6340, avg score : 689.5\n",
      "# of episode : 6360, avg score : 844.0\n",
      "# of episode : 6380, avg score : 1169.55\n",
      "# of episode : 6400, avg score : 1176.9\n",
      "# of episode : 6420, avg score : 1138.45\n",
      "# of episode : 6440, avg score : 1075.95\n",
      "# of episode : 6460, avg score : 1201.85\n",
      "# of episode : 6480, avg score : 1323.1\n",
      "# of episode : 6500, avg score : 1217.35\n",
      "# of episode : 6520, avg score : 2801.4\n",
      "# of episode : 6540, avg score : 3856.5\n",
      "# of episode : 6560, avg score : 2705.0\n",
      "# of episode : 6580, avg score : 2459.45\n",
      "# of episode : 6600, avg score : 2296.85\n",
      "# of episode : 6620, avg score : 3508.9\n",
      "# of episode : 6640, avg score : 4643.5\n",
      "# of episode : 6660, avg score : 4824.4\n",
      "# of episode : 6680, avg score : 8573.85\n",
      "# of episode : 6700, avg score : 7590.15\n",
      "# of episode : 6720, avg score : 6836.55\n",
      "# of episode : 6740, avg score : 6476.45\n",
      "# of episode : 6760, avg score : 5872.8\n",
      "# of episode : 6780, avg score : 6494.5\n",
      "# of episode : 6800, avg score : 8631.1\n",
      "# of episode : 6820, avg score : 4301.65\n",
      "# of episode : 6840, avg score : 3775.2\n",
      "# of episode : 6860, avg score : 3468.65\n",
      "# of episode : 6880, avg score : 4059.9\n",
      "# of episode : 6900, avg score : 2553.55\n",
      "# of episode : 6920, avg score : 2909.8\n",
      "# of episode : 6940, avg score : 1420.85\n",
      "# of episode : 6960, avg score : 1036.75\n",
      "# of episode : 6980, avg score : 778.75\n",
      "# of episode : 7000, avg score : 1271.7\n",
      "# of episode : 7020, avg score : 1997.2\n",
      "# of episode : 7040, avg score : 3087.15\n",
      "# of episode : 7060, avg score : 1535.3\n",
      "# of episode : 7080, avg score : 1718.85\n",
      "# of episode : 7100, avg score : 1606.6\n",
      "# of episode : 7120, avg score : 3228.0\n",
      "# of episode : 7140, avg score : 8461.1\n",
      "# of episode : 7160, avg score : 3714.25\n",
      "# of episode : 7180, avg score : 1826.55\n",
      "# of episode : 7200, avg score : 1092.9\n",
      "# of episode : 7220, avg score : 1438.45\n",
      "# of episode : 7240, avg score : 2367.45\n",
      "# of episode : 7260, avg score : 9175.95\n",
      "# of episode : 7280, avg score : 10389.35\n",
      "# of episode : 7300, avg score : 10487.85\n",
      "# of episode : 7320, avg score : 14395.0\n",
      "# of episode : 7340, avg score : 15661.15\n",
      "# of episode : 7360, avg score : 16784.95\n",
      "# of episode : 7380, avg score : 19968.35\n",
      "# of episode : 7400, avg score : 11191.0\n",
      "# of episode : 7420, avg score : 8228.6\n",
      "# of episode : 7440, avg score : 6662.9\n",
      "# of episode : 7460, avg score : 4057.35\n",
      "# of episode : 7480, avg score : 5548.45\n",
      "# of episode : 7500, avg score : 8019.7\n",
      "# of episode : 7520, avg score : 1842.1\n",
      "# of episode : 7540, avg score : 1177.7\n",
      "# of episode : 7560, avg score : 1450.4\n",
      "# of episode : 7580, avg score : 2064.65\n",
      "# of episode : 7600, avg score : 5130.0\n",
      "# of episode : 7620, avg score : 5007.9\n",
      "# of episode : 7640, avg score : 8572.55\n",
      "# of episode : 7660, avg score : 16450.45\n",
      "# of episode : 7680, avg score : 19812.25\n",
      "# of episode : 7700, avg score : 28000.55\n",
      "# of episode : 7720, avg score : 25468.2\n",
      "# of episode : 7740, avg score : 5291.45\n",
      "# of episode : 7760, avg score : 3965.75\n",
      "# of episode : 7780, avg score : 2940.7\n",
      "# of episode : 7800, avg score : 2191.6\n",
      "# of episode : 7820, avg score : 2256.95\n",
      "# of episode : 7840, avg score : 1445.3\n",
      "# of episode : 7860, avg score : 1131.7\n",
      "# of episode : 7880, avg score : 1054.75\n",
      "# of episode : 7900, avg score : 1571.95\n",
      "# of episode : 7920, avg score : 3417.05\n",
      "# of episode : 7940, avg score : 9421.45\n",
      "# of episode : 7960, avg score : 7547.95\n",
      "# of episode : 7980, avg score : 9693.0\n",
      "# of episode : 8000, avg score : 10716.35\n",
      "# of episode : 8020, avg score : 7017.65\n",
      "# of episode : 8040, avg score : 8818.5\n",
      "# of episode : 8060, avg score : 7871.25\n",
      "# of episode : 8080, avg score : 5472.4\n",
      "# of episode : 8100, avg score : 8231.9\n",
      "# of episode : 8120, avg score : 16639.15\n",
      "# of episode : 8140, avg score : 18850.05\n",
      "# of episode : 8160, avg score : 18396.75\n",
      "# of episode : 8180, avg score : 9089.85\n",
      "# of episode : 8200, avg score : 7183.0\n",
      "# of episode : 8220, avg score : 6074.95\n",
      "# of episode : 8240, avg score : 6020.6\n",
      "# of episode : 8260, avg score : 4005.85\n",
      "# of episode : 8280, avg score : 2920.9\n",
      "# of episode : 8300, avg score : 1854.5\n",
      "# of episode : 8320, avg score : 2106.6\n",
      "# of episode : 8340, avg score : 1919.9\n",
      "# of episode : 8360, avg score : 3838.95\n",
      "# of episode : 8380, avg score : 4791.4\n",
      "# of episode : 8400, avg score : 4466.3\n",
      "# of episode : 8420, avg score : 2172.8\n",
      "# of episode : 8440, avg score : 1729.55\n",
      "# of episode : 8460, avg score : 2083.35\n",
      "# of episode : 8480, avg score : 1796.15\n",
      "# of episode : 8500, avg score : 1842.9\n",
      "# of episode : 8520, avg score : 2682.8\n",
      "# of episode : 8540, avg score : 5098.35\n",
      "# of episode : 8560, avg score : 4228.9\n",
      "# of episode : 8580, avg score : 6229.55\n",
      "# of episode : 8600, avg score : 5387.0\n",
      "# of episode : 8620, avg score : 5000.55\n",
      "# of episode : 8640, avg score : 3947.45\n",
      "# of episode : 8660, avg score : 4748.1\n",
      "# of episode : 8680, avg score : 9493.15\n",
      "# of episode : 8700, avg score : 21760.7\n",
      "# of episode : 8720, avg score : 49809.65\n",
      "# of episode : 8740, avg score : 60117.3\n",
      "# of episode : 8760, avg score : 25022.35\n",
      "# of episode : 8780, avg score : 18570.7\n",
      "# of episode : 8800, avg score : 20017.3\n",
      "# of episode : 8820, avg score : 11313.5\n",
      "# of episode : 8840, avg score : 11048.45\n",
      "# of episode : 8860, avg score : 16833.65\n",
      "# of episode : 8880, avg score : 12758.2\n",
      "# of episode : 8900, avg score : 20368.75\n",
      "# of episode : 8920, avg score : 18744.35\n",
      "# of episode : 8940, avg score : 31946.3\n",
      "# of episode : 8960, avg score : 22215.2\n",
      "# of episode : 8980, avg score : 34480.55\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    pi = Policy()\n",
    "    score = 0.0\n",
    "    print_interval = 20\n",
    "    br = True\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        start_time = time.time()\n",
    "        s, _ = env.reset() # s = 길이 4 벡터\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if time.time() - start_time > 600 : # 강제 종료 조건 삽입\n",
    "                br = False\n",
    "                break\n",
    "            prob = pi(torch.from_numpy(s).float()) # prob : tensor([0.4491, 0.5509], grad_fn=<SoftmaxBackward0>)\n",
    "            m = Categorical(prob)\n",
    "            a = m.sample() # a: tensor(1) /  각 Category에 대한 확률을 계산하고, 그 중 하나를 뽑는다.(type : tensor) / a = 0 or 1\n",
    "            # prob가 높은 action은 더 자주, prob가 낮은 action은 덜 뽑히게 된다.\n",
    "            s_prime, r, done, truncat1ed, info = env.step(a.item()) # a.item() : tensor를 int로 바꿔준다.\n",
    "            # 이때 r = 1. 따라서 최대한 오랜 시간 동안 CartPole을 유지하도록 학습\n",
    "            pi.put_data((r, prob[a])) # r : 1 / prob[a] : tensor(0.5509)\n",
    "            s = s_prime\n",
    "            score += r\n",
    "        \n",
    "        if br == False:\n",
    "            break\n",
    "\n",
    "        pi.train_net() # episode가 끝나면 하나의 episode동안 모은 데이터를 이용해 Parameter(theta) Update를 진행\n",
    "        \n",
    "        if n_epi % print_interval == 0 and n_epi != 0: # 20번의 episode마다 avg score 출력\n",
    "            print(\"# of episode : {}, avg score : {}\".format(n_epi, score / print_interval))\n",
    "            score = 0.0\n",
    "            \n",
    "    env.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정책 기반 에이전트 - TD Actor - Critic 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TD Actor-Critic algorithm for CartPole 동작 과정 요약 (On-policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 라이브러리 Import 및 하이퍼 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions import Categorical\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.0002\n",
    "gamma = 0.98\n",
    "n_rollout = 10 # 몇 틱의 데이터를 쌓아서 업데이트 할지를 나타냄(여기서는 10번의 transition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 액터 크리틱 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.data = []\n",
    "\n",
    "        self.fc1 = nn.Linear(4, 256)\n",
    "        # 256개의 노드로 이루어진 첫 번째 Layer는 Actor와 Critic의 공통 Layer(정책 네트워크 업데이트 때도, 밸류 네트워크 업데이트에서도 항상 업데이트됨)\n",
    "        self.fc_pi = nn.Linear(256, 2)\n",
    "        self.fc_v = nn.Linear(256, 1)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "\n",
    "    def pi(self, x, softmax_dim = 0):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim = softmax_dim)\n",
    "        return prob\n",
    "    \n",
    "    def v(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "    \n",
    "    def put_data(self, transition):\n",
    "        self.data.append(transition)\n",
    "\n",
    "    def make_batch(self): # n_rollout만큼의 data들을 분리해서 mini batch를 만들어줌\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, done = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r / 100.0])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            done_lst.append([done_mask])\n",
    "\n",
    "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype = torch.float), torch.tensor(a_lst), \\\n",
    "            torch.tensor(r_lst, dtype = torch.float), torch.tensor(s_prime_lst, dtype = torch.float), torch.tensor(done_lst, dtype = torch.float)\n",
    "        self.data = []\n",
    "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
    "    \n",
    "    def train_net(self):\n",
    "        s, a, r, s_prime, done = self.make_batch() # 각각 n_rollout만큼의 데이터를 가지고 있음\n",
    "        td_target = r + gamma * self.v(s_prime) * done\n",
    "        delta = td_target - self.v(s) # baseline을 빼줌 (value network의 loss)\n",
    "\n",
    "        pi = self.pi(s, softmax_dim = 1)\n",
    "        pi_a = pi.gather(1, a)\n",
    "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(self.v(s), td_target.detach()) # 정책 네트워크의 손실 함수와 밸류 네트워크의 손실 함수를 더하여 한 번에 업데이트를 진행\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.mean().backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 메인 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    env = gym.make('CartPole-v1')\n",
    "    model = ActorCritic()\n",
    "    print_interval = 20\n",
    "    score = 0.0\n",
    "\n",
    "    for n_epi in range(10000):\n",
    "        done = False\n",
    "        s = env.reset()\n",
    "\n",
    "        while not done:\n",
    "            for t in range(n_rollout): # n_rollout : 10\n",
    "                prob = model.pi(torch.from_numpy(s).float()) # action을 선택(이때, prob는 2개의 action에 대한 확률값)\n",
    "                m = Categorical(prob)\n",
    "                a = m.sample().item()\n",
    "                s_prime, r, done, info = env.step(a)\n",
    "                model.put_data((s, a, r, s_prime, done)) # n_rollout만큼의 transition을 저장\n",
    "\n",
    "                s = s_prime\n",
    "                score += r\n",
    "\n",
    "                if done : break\n",
    "\n",
    "            model.train_net()\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            print(\"# of episode : {}, avg score : {}\".format(n_epi, score / print_interval))\n",
    "            score = 0.0\n",
    "\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
